{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yunsun2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yunsun2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunsun2\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk   \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import PorterStemmer, WordNetLemmatizer \n",
    "\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:/Users/Yunsun2/Desktop/Github/yelp_cleaned.csv', encoding='latin-1', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              stars      cool    useful     funny  text_len  sentiment\n",
      "stars      1.000000  0.052555 -0.023479 -0.061306 -0.092193   0.492147\n",
      "cool       0.052555  1.000000  0.887102  0.764342  0.237975   0.060880\n",
      "useful    -0.023479  0.887102  1.000000  0.723406  0.290306   0.028723\n",
      "funny     -0.061306  0.764342  0.723406  1.000000  0.242552  -0.022380\n",
      "text_len  -0.092193  0.237975  0.290306  0.242552  1.000000   0.063492\n",
      "sentiment  0.492147  0.060880  0.028723 -0.022380  0.063492   1.000000\n"
     ]
    }
   ],
   "source": [
    "#Sentiment analysis;\n",
    "def sentiment_score(text):\n",
    "    neg_words={'awkwardly', 'awkward', 'butt', 'discount', 'disappointed', 'disappoint', \n",
    "               'dismay', 'dumb', 'manner', 'sue', 'mean', 'meeting', 'monte', 'unfriendly', 'nasty', 'refuse', \n",
    "               'avoid', 'soggy', 'mistake', 'upset', 'filthy', 'sad', 'lousy', 'worst',  'unprofessional', \n",
    "               'rudely','unfortunately', 'screw', 'poorly', 'crap', 'crappy', 'tasteless', 'ignore', 'disaster',\n",
    "               'overpriced', 'wrong', 'sick', 'inedible', 'stale', 'dirty', 'disappointment', 'sorry', 'yuck', \n",
    "               'flavorless', 'mess', 'dont', 'slow', 'lack', 'wouldnt', 'disappointed', 'terrible', 'overprice', \n",
    "               'gross', 'waste', 'poor', 'leave', 'disgust', 'awful', 'mediocre', 'suck', 'bland', 'wasnt', \n",
    "               'rude', 'didnt', 'horrible', 'bad'}\n",
    "                   \n",
    "    pos_words={'ambiance', 'ambience', 'awhile', 'delight', 'generous', 'hilarious', 'homey', 'hometown', 'home'\n",
    "               'performance', 'performer', 'recover', 'tremendous', 'fantastically', 'fantastic', 'friendly', 'funny', \n",
    "               'goodwill', 'successfully', 'amaze', 'amazing', 'amazingly', 'magic', 'favourite', 'favorite', 'extraordinarily'\n",
    "               'great', 'love', 'best', 'delicious', 'perfect', 'awesome', 'recommend', 'excellent', 'highly', 'fresh', \n",
    "               'friendly', 'wonderful', 'perfectly', 'like', 'beautiful', 'fabulous', 'cool', 'super', 'heaven', 'incredible'}   \n",
    "    \n",
    "    score=0\n",
    "    for i in str(text).split():\n",
    "        if i in pos_words:\n",
    "            score+=1\n",
    "        elif i in neg_words:\n",
    "            score-=1\n",
    "    return score\n",
    "    \n",
    "data['sentiment']=data['textc'].apply(sentiment_score)\n",
    "print(data.corr())  #sentiment now is 0.49 corr with stars; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3526\n",
       "5    3337\n",
       "3    1461\n",
       "2     927\n",
       "1     749\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#re-value stars 4 & 5\n",
    "data['star']=data['stars'].apply(lambda x: 5 if x>=4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop('stars', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "Z=data.drop('textc', axis=1)\n",
    "X=data['textc'] #will add other features back later on for another analysis;   \n",
    "\n",
    "rs=3746\n",
    "x_train, x_test, ztrain, ztest = train_test_split(X, Z, test_size=0.3, random_state=rs) \n",
    "\n",
    "#TfidfVectorizer\n",
    "tfidfv=TfidfVectorizer(min_df=2, ngram_range=(1, 1), stop_words='english', max_features=10000, strip_accents='unicode', \n",
    "                           norm='l2')\n",
    "\n",
    "xtrain=tfidfv.fit_transform(x_train.values.astype('U')).todense()\n",
    "xtest=tfidfv.transform(x_test.values.astype('U')).todense()\n",
    "col = ['feat_'+i for i in tfidfv.get_feature_names()]  #for TfidfVectorizer\n",
    "\n",
    "_xtrain = pd.DataFrame(xtrain, columns=col)  #feature names added\n",
    "_xtest = pd.DataFrame(xtest, columns=col)  #row index from 0 to 6999 (number of reviews);  \n",
    "\n",
    "temptrain=ztrain.loc[:, ['cool', 'useful', 'funny', 'text_len', 'sentiment']].reset_index(drop=True)  #remove 'sentiment' needed;\n",
    "trainfull=pd.concat([temptrain, _xtrain], axis=1)\n",
    "\n",
    "temptest=ztest.loc[:, ['cool', 'useful', 'funny', 'text_len', 'sentiment']].reset_index(drop=True) #remove 'sentiment' needed;\n",
    "testfull=pd.concat([temptest, _xtest], axis=1)\n",
    "\n",
    "ytrain=ztrain['star']\n",
    "ytest=ztest['star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression predictions with default hyparameters for Test\n",
      "\n",
      "Accuracy\n",
      "0.718666666667\n",
      "[[  71   33   13  112]\n",
      " [  34   43   25  167]\n",
      " [  15   25   56  381]\n",
      " [   8    5   26 1986]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.31      0.40       229\n",
      "          2       0.41      0.16      0.23       269\n",
      "          3       0.47      0.12      0.19       477\n",
      "          5       0.75      0.98      0.85      2025\n",
      "\n",
      "avg / total       0.66      0.72      0.65      3000\n",
      "\n",
      "LogisticRegressionpredictions with default hyparameters for Train\n",
      "\n",
      "Accuracy\n",
      "0.804714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "result=pd.DataFrame()\n",
    "rs=1928\n",
    "global result\n",
    "\n",
    "'''\n",
    "model=RandomForestRegressor(random_state=rs)\n",
    "cname='RandomForestRegressor'\n",
    "\n",
    "model=XGBClassifier(random_state=rs)\n",
    "cname='XGBoost'\n",
    "'''\n",
    "model=LogisticRegression(random_state=rs)\n",
    "cname='LogisticRegression'\n",
    "\n",
    "model.fit(trainfull, ytrain)\n",
    "pred=model.predict(testfull)\n",
    "tpred=model.predict(trainfull)\n",
    "    \n",
    "#RFRegressor has not attributes of predict_proba; \n",
    "predproba=pd.DataFrame(model.predict_proba(testfull))\n",
    "tpredproba=pd.DataFrame(model.predict_proba(trainfull))\n",
    "#merge with test and train labels; \n",
    "\n",
    "print(cname + ' predictions with default hyparameters for Test'+'\\n')\n",
    "print('Accuracy')\n",
    "print(accuracy_score(ytest, pred, normalize=True))\n",
    "print(confusion_matrix(ytest, pred))\n",
    "print(classification_report(ytest, pred))  \n",
    "\n",
    "print(cname + 'predictions with default hyparameters for Train'+'\\n')\n",
    "print('Accuracy')\n",
    "print(accuracy_score(ytrain, tpred, normalize=True))\n",
    "\n",
    "#compare bad predictions of different models; \n",
    "result=pd.concat([result, pd.DataFrame(pred)], axis=1) #to merge the predicted labels back to the dataset;\n",
    "result.rename(columns={0:str(cname + '_pred')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression predictions with default hyparameters for Test\n",
      "\n",
      "Accuracy\n",
      "0.718666666667\n",
      "[[  71   33   13  112]\n",
      " [  34   43   25  167]\n",
      " [  15   25   56  381]\n",
      " [   8    5   26 1986]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.31      0.40       229\n",
      "          2       0.41      0.16      0.23       269\n",
      "          3       0.47      0.12      0.19       477\n",
      "          5       0.75      0.98      0.85      2025\n",
      "\n",
      "avg / total       0.66      0.72      0.65      3000\n",
      "\n",
      "LogisticRegressionpredictions with default hyparameters for Train\n",
      "\n",
      "Accuracy\n",
      "0.804714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "result=pd.DataFrame()\n",
    "rs=300\n",
    "global result\n",
    "\n",
    "'''\n",
    "model=RandomForestRegressor(random_state=rs)\n",
    "cname='RandomForestRegressor'\n",
    "\n",
    "model=XGBClassifier(random_state=rs)\n",
    "cname='XGBoost'\n",
    "'''\n",
    "model=LogisticRegression(random_state=rs)\n",
    "cname='LogisticRegression'\n",
    "\n",
    "model.fit(trainfull, ytrain)\n",
    "pred=model.predict(testfull)\n",
    "tpred=model.predict(trainfull)\n",
    "    \n",
    "#RFRegressor has not attributes of predict_proba; \n",
    "predproba=pd.DataFrame(model.predict_proba(testfull))\n",
    "tpredproba=pd.DataFrame(model.predict_proba(trainfull))\n",
    "#merge with test and train labels; \n",
    "\n",
    "print(cname + ' predictions with default hyparameters for Test'+'\\n')\n",
    "print('Accuracy')\n",
    "print(accuracy_score(ytest, pred, normalize=True))\n",
    "print(confusion_matrix(ytest, pred))\n",
    "print(classification_report(ytest, pred))  \n",
    "\n",
    "print(cname + 'predictions with default hyparameters for Train'+'\\n')\n",
    "print('Accuracy')\n",
    "print(accuracy_score(ytrain, tpred, normalize=True))\n",
    "\n",
    "#compare bad predictions of different models; \n",
    "result=pd.concat([result, pd.DataFrame(pred)], axis=1) #to merge the predicted labels back to the dataset;\n",
    "result.rename(columns={0:str(cname + '_pred')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Much better now! Star 5 and Star 1 greatly improved. \n",
    "#Can do more sentiment/error analysis to see why star 103 has been much mis-classified to 4/5 (5 now)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
