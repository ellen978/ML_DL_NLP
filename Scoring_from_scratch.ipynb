{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(csvfile):\n",
    "    import psutil\n",
    "    import os\n",
    "    import time\n",
    "    \n",
    "    #System status; \n",
    "    print('Initial memory:')\n",
    "    print(psutil.virtual_memory().percent/100)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    %matplotlib inline\n",
    "    import re\n",
    "    import string\n",
    "    import pickle\n",
    "\n",
    "    #from sklearn.cross_validation import train_test_split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn import linear_model\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    \n",
    "    #Pre-processing; \n",
    "    data=pd.read_csv(csvfile)\n",
    "    \n",
    "    constant_feat=['x067', 'x094', 'x095', 'x096'] #assume holdout data also has these 4 features w/ only constant values.\n",
    "    data.drop(constant_feat, axis=1, inplace=True)\n",
    "    \n",
    "    with open('trainmedian.pickle', 'rb') as f:\n",
    "        data.fillna(pickle.load(f), inplace=True)\n",
    "\n",
    "    #Predictions; \n",
    "    X=data.drop('y', axis=1)\n",
    "    y=data['y']  \n",
    "    \n",
    "    with open('wh_pred.pickle', 'rb') as f:\n",
    "        regr=pickle.load(f)\n",
    "        y_pred = regr.predict(X)\n",
    "    \n",
    "    #Evaluations; \n",
    "    y_preddummy=(abs(y_pred-y)<=3)\n",
    "    RSME=np.sqrt(mean_squared_error(y, y_pred))\n",
    "    R2=r2_score(y, y_pred)\n",
    "    Accu=y_preddummy.value_counts()/len(y_preddummy)\n",
    "    perf = [RSME, R2, Accu[True]]\n",
    "    performance_metric = pd.DataFrame(perf, index=['RSME', 'R-squared', 'Accuracy'], columns=['Value']) #smaller, bigger, bigger; \n",
    "    \n",
    "    #Outputs; \n",
    "    pd.DataFrame(performance_metric).to_csv('performance_metric.txt', sep='\\t', header=True, index=True)\n",
    "    pd.DataFrame(y_pred).to_csv('y_pred.txt', sep='\\t', header=False, index=True)\n",
    "    \n",
    "    #System status; \n",
    "    print('Memory after model output:')\n",
    "    print(psutil.virtual_memory().percent/100)\n",
    "    print(\"--- Processing time %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory:\n",
      "0.634\n",
      "Memory after model output:\n",
      "0.693\n",
      "--- Processing time 5.268308877944946 seconds ---\n"
     ]
    }
   ],
   "source": [
    "scoring('holdout.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSummary of the analysis\\n1. Assumptions \\n    Both the regressors and the imputed median values of the training dataset should be applied to future hold-out data together. \\n    Also assume the hold-out dataset has the same data problems with the data provided: 4 single valued features ('x067', 'x094', 'x095', 'x096').\\n\\n2. Steps and algorithms\\n    First remove 4 single-valued features, which provide no prediction power to the model: 'x067', 'x094', 'x095', 'x096'.\\n    Then split the dataset into 70% trainig and 30% test.\\n    For features with missing values, impute the median values of the corresponding feature from available training dataset into both training and test dataset to make the dataset fully available to use.\\n    Due to the limited computing power of my personal computer, here adopted only the model of RandomForestRegressor with 500 trees. \\n    Three performance metrics are adopted: RSME, R-squared, accuracy rate (considering absolute error within 3 as 'accurate').\\n    Save the median values and regressor in pickle files, to use to run in a separate file for future scoring. \\n\\n3. My personal computer hardware specification:\\n    RAM: 4 GB 1600 MHz DDR3\\n    Processor: 1.4 GHz Intel Core i5\\n\\n4. Estimated memory time needed by the program \\n    Running 100,000 data points as test, 15% of virtual memory and time of 62 seconds have been used on the computer (specified above).\\n\\n5. Output files generated by the program\\n    Two text files are created: \\n        y_pred.txt will include 100,000 predictions of the hold-out dataset.\\n        performance_metric.txt will include 3 performance measures. \\n\\n6. To run this program: \\n    Save 3 files at the same location with hold-out csv file: wh_pred.pickle, trainmedian.pickle, Scoring_from_scratch.py. \\n    Providing the name of hold-out csv file to the 'scoring' function of the program (Scoring_from_scratch.py), the program will run and generate 2 output files. \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Summary of the analysis\n",
    "1. Assumptions \n",
    "    Both the regressors and the imputed median values of the training dataset should be applied to future hold-out data together. \n",
    "    Also assume the hold-out dataset has the same data problems with the data provided: 4 single valued features ('x067', 'x094', 'x095', 'x096').\n",
    "\n",
    "2. Steps and algorithms\n",
    "    First remove 4 single-valued features, which provide no prediction power to the model: 'x067', 'x094', 'x095', 'x096'.\n",
    "    Then split the dataset into 70% trainig and 30% test.\n",
    "    For features with missing values, impute the median values of the corresponding feature from available training dataset into both training and test dataset to make the dataset fully available to use.\n",
    "    Due to the limited computing power of my personal computer, here adopted only the model of RandomForestRegressor with 500 trees. \n",
    "    Three performance metrics are adopted: RSME, R-squared, accuracy rate (considering absolute error within 3 as 'accurate').\n",
    "    Save the median values and regressor in pickle files, to use to run in a separate file for future scoring. \n",
    "\n",
    "3. My personal computer hardware specification:\n",
    "    RAM: 4 GB 1600 MHz DDR3\n",
    "    Processor: 1.4 GHz Intel Core i5\n",
    "\n",
    "4. Estimated memory time needed by the program \n",
    "    Running 100,000 data points as test, 15% of virtual memory and time of 62 seconds have been used on the computer (specified above).\n",
    "\n",
    "5. Output files generated by the program\n",
    "    Two text files are created: \n",
    "        y_pred.txt will include 100,000 predictions of the hold-out dataset.\n",
    "        performance_metric.txt will include 3 performance measures. \n",
    "\n",
    "6. To run this program: \n",
    "    Save 3 files at the same location with hold-out csv file: wh_pred.pickle, trainmedian.pickle, Scoring_from_scratch.py. \n",
    "    Providing the name of hold-out csv file to the 'scoring' function of the program (Scoring_from_scratch.py), the program will run and generate 2 output files. \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
