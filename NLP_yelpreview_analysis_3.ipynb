{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yunsun2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yunsun2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk   \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import PorterStemmer, WordNetLemmatizer \n",
    "\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:/Users/Yunsun2/Desktop/Github/yelp_cleaned.csv', encoding='latin-1', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052555</td>\n",
       "      <td>-0.023479</td>\n",
       "      <td>-0.061306</td>\n",
       "      <td>-0.092193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cool</th>\n",
       "      <td>0.052555</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887102</td>\n",
       "      <td>0.764342</td>\n",
       "      <td>0.237975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>useful</th>\n",
       "      <td>-0.023479</td>\n",
       "      <td>0.887102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.723406</td>\n",
       "      <td>0.290306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>-0.061306</td>\n",
       "      <td>0.764342</td>\n",
       "      <td>0.723406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.242552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_len</th>\n",
       "      <td>-0.092193</td>\n",
       "      <td>0.237975</td>\n",
       "      <td>0.290306</td>\n",
       "      <td>0.242552</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             stars      cool    useful     funny  text_len\n",
       "stars     1.000000  0.052555 -0.023479 -0.061306 -0.092193\n",
       "cool      0.052555  1.000000  0.887102  0.764342  0.237975\n",
       "useful   -0.023479  0.887102  1.000000  0.723406  0.290306\n",
       "funny    -0.061306  0.764342  0.723406  1.000000  0.242552\n",
       "text_len -0.092193  0.237975  0.290306  0.242552  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_train).iloc[1, 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "Z=data.drop('textc', axis=1)\n",
    "X=data['textc'] #will add other features back later on for another analysis;   \n",
    "\n",
    "rs=9876\n",
    "x_train, x_test, ztrain, ztest = train_test_split(X, Z, test_size=0.3, random_state=rs) \n",
    "\n",
    "\n",
    "#TfidfVectorizer\n",
    "tfidfv=TfidfVectorizer(min_df=2, ngram_range=(1, 1), stop_words='english', max_features=10000, strip_accents='unicode', \n",
    "                           norm='l2')\n",
    "\n",
    "xtrain=tfidfv.fit_transform(x_train.values.astype('U')).todense()\n",
    "xtest=tfidfv.transform(x_test.values.astype('U')).todense()\n",
    "col = ['feat_'+i for i in tfidfv.get_feature_names()]  #for TfidfVectorizer\n",
    "\n",
    "\n",
    "_xtrain = pd.DataFrame(xtrain, columns=col)  #feature names added\n",
    "_xtest = pd.DataFrame(xtest, columns=col)  #row index from 0 to 6999 (number of reviews);  \n",
    "\n",
    "temptrain=ztrain.loc[:, ['cool', 'useful', 'funny', 'text_len', 'sentiment']].reset_index(drop=True)  #remove 'sentiment' needed;\n",
    "trainfull=pd.concat([temptrain, _xtrain], axis=1)\n",
    "\n",
    "temptest=ztest.loc[:, ['cool', 'useful', 'funny', 'text_len', 'sentiment']].reset_index(drop=True) #remove 'sentiment' needed;\n",
    "testfull=pd.concat([temptest, _xtest], axis=1)\n",
    "\n",
    "ytrain=ztrain['stars']\n",
    "ytest=ztest['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression predictions with default hyparameters for Test\n",
      "\n",
      "Accuracy\n",
      "0.519666666667\n",
      "[[113  17  29  42  44]\n",
      " [ 53  38  40 115  40]\n",
      " [ 14  17  78 258  77]\n",
      " [  8   4  37 642 337]\n",
      " [  3   3   3 300 688]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.46      0.52       245\n",
      "          2       0.48      0.13      0.21       286\n",
      "          3       0.42      0.18      0.25       444\n",
      "          4       0.47      0.62      0.54      1028\n",
      "          5       0.58      0.69      0.63       997\n",
      "\n",
      "avg / total       0.51      0.52      0.49      3000\n",
      "\n",
      "LogisticRegressionpredictions with default hyparameters for Train\n",
      "\n",
      "Accuracy\n",
      "0.703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "result=pd.DataFrame()\n",
    "rs=300\n",
    "global result\n",
    "\n",
    "'''\n",
    "model=RandomForestRegressor(random_state=rs)\n",
    "cname='RandomForestRegressor'\n",
    "\n",
    "model=XGBClassifier(random_state=rs)\n",
    "cname='XGBoost'\n",
    "'''\n",
    "model=LogisticRegression(random_state=rs)\n",
    "cname='LogisticRegression'\n",
    "\n",
    "\n",
    "model.fit(trainfull, ytrain)\n",
    "pred=model.predict(testfull)\n",
    "tpred=model.predict(trainfull)\n",
    "    \n",
    "\n",
    "#RFRegressor has not attributes of predict_proba; \n",
    "predproba=pd.DataFrame(model.predict_proba(testfull))\n",
    "tpredproba=pd.DataFrame(model.predict_proba(trainfull))\n",
    "#merge with test and train labels; \n",
    "\n",
    "print(cname + ' predictions with default hyparameters for Test'+'\\n')\n",
    "print('Accuracy')\n",
    "print(accuracy_score(ytest, pred, normalize=True))\n",
    "print(confusion_matrix(ytest, pred))\n",
    "print(classification_report(ytest, pred))  \n",
    "\n",
    "print(cname + 'predictions with default hyparameters for Train'+'\\n')\n",
    "print('Accuracy')\n",
    "print(accuracy_score(ytrain, tpred, normalize=True))\n",
    "\n",
    "#compare bad predictions of different models; \n",
    "result=pd.concat([result, pd.DataFrame(pred)], axis=1) #to merge the predicted labels back to the dataset;\n",
    "result.rename(columns={0:str(cname + '_pred')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.415333333333\n",
      "[[114  45  54  19  13]\n",
      " [ 88  64  79  39  16]\n",
      " [ 32  73 155 137  47]\n",
      " [ 21  41 262 387 317]\n",
      " [ 13  28 132 298 526]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.47      0.44       245\n",
      "          2       0.25      0.22      0.24       286\n",
      "          3       0.23      0.35      0.28       444\n",
      "          4       0.44      0.38      0.41      1028\n",
      "          5       0.57      0.53      0.55       997\n",
      "\n",
      "avg / total       0.43      0.42      0.42      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########For RandomForest Regressor ONLY; \n",
    "###Stars 1, 2, 3 improves significantly, but stars 4 & 5, very hard to differentiate thus hard to adjust the threshold;\n",
    "###Suggest to combine 4 & 5\n",
    "'''\n",
    "rtest=pd.DataFrame(ytest).reset_index(drop=True)\n",
    "rltest=pd.concat([rtest, pd.DataFrame(pred)], axis=1) #result & labels; \n",
    "rltest.rename(columns={0:'reg_pred'}, inplace=True)\n",
    "for i in [5, 4, 3, 2, 1]:\n",
    "    print('star ' + str(i))\n",
    "    print(rltest[rltest['stars']==i]['reg_pred'].describe())\n",
    "#star 4 and 5 are very close, so as star 1 & 2; \n",
    "'''\n",
    "#to define the regressor; \n",
    "def pred_gen(reg_value):\n",
    "    if reg_value>4.3:\n",
    "        return 5\n",
    "    elif 3.8<reg_value<=4.3:\n",
    "        return 4\n",
    "    elif 3.0<reg_value<=3.8:\n",
    "        return 3\n",
    "    elif 2.4<reg_value<=3.0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "pred2=pd.DataFrame(pred)\n",
    "pred2.rename(columns={0:'regpred'}, inplace=True)\n",
    "pred2['predstar']=pred2['regpred'].apply(pred_gen)\n",
    "pred2.head()\n",
    "\n",
    "len(ytest)\n",
    "ytst=ytest.reset_index(drop=True)\n",
    "testres_all=pd.concat([ytst, pred2], axis=1)\n",
    "testres_all.groupby(['stars', 'predstar']).count()\n",
    "\n",
    "print('Accuracy')\n",
    "print(accuracy_score(ytest, testres_all['predstar'], normalize=True))\n",
    "print(confusion_matrix(ytest, testres_all['predstar']))\n",
    "print(classification_report(ytest, testres_all['predstar'])) \n",
    "\n",
    "#testres_all[(testres_all['stars']==4) & (testres_all['predstar']!=4)]['regpred'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star: 4\n",
      "87\n",
      "star: 5\n",
      "77\n",
      "star: 3\n",
      "55\n",
      "star: 1\n",
      "29\n",
      "star: 2\n",
      "63\n",
      "              stars  sentiment\n",
      "stars      1.000000   0.449947\n",
      "sentiment  0.449947   1.000000\n"
     ]
    }
   ],
   "source": [
    "#Sentiment analysis;\n",
    "#dic of feature: coef pairs for star=1\n",
    "for i in [3, 4, 2, 0, 1]:\n",
    "    print('star: '+str(i+1))\n",
    "    feature_to_coef = {word: coef for word, coef in zip(tfidfv.get_feature_names(), model.coef_[i, :])}   \n",
    "        #i indicates which star, i=0,1,2,3 & star=1, 2, 3, 4\n",
    "    keyfeas=[(k, v) for k, v in feature_to_coef.items() if 0.75<v<1]\n",
    "    #print(keyfeas)\n",
    "    print(len(keyfeas))\n",
    "\n",
    "def sentiment_score(text):\n",
    "    neg_words={'awkwardly', 'awkward', 'butt', 'discount', 'disappointed', 'disappoint', \n",
    "               'dismay', 'dumb', 'manner', 'sue', 'mean', 'meeting', 'monte', 'unfriendly', 'nasty', 'refuse', \n",
    "               'avoid', 'soggy', 'mistake', 'upset', 'filthy', 'sad', 'lousy', 'worst',  'unprofessional', \n",
    "               'rudely','unfortunately', 'screw', 'poorly', 'crap', 'crappy', 'tasteless', 'ignore', 'disaster',\n",
    "               'overpriced', 'wrong', 'sick', 'inedible', 'stale', 'dirty', 'disappointment', 'sorry', 'yuck', \n",
    "               'flavorless', 'mess', 'dont', 'slow', 'lack', 'wouldnt', 'disappointed', 'terrible', 'overprice', \n",
    "               'gross', 'waste', 'poor', 'leave', 'disgust', 'awful', 'mediocre', 'suck', 'bland', 'wasnt', \n",
    "               'rude', 'didnt', 'horrible', 'bad'}\n",
    "                   \n",
    "    pos_words={'ambiance', 'ambience', 'awhile', 'delight', 'generous', 'hilarious', 'homey', 'hometown', 'home'\n",
    "               'performance', 'performer', 'recover', 'tremendous', 'fantastically', 'fantastic', 'friendly', 'funny', \n",
    "               'goodwill', 'successfully', 'amaze', 'amazing', 'amazingly', 'magic', 'favourite', 'favorite', 'extraordinarily'\n",
    "               'great', 'love', 'best', 'delicious', 'perfect', 'awesome', 'recommend', 'excellent', 'highly', 'fresh', \n",
    "               'friendly', 'wonderful', 'perfectly', 'like', 'beautiful', 'fabulous', 'cool', 'super', 'heaven', 'incredible'}   \n",
    "    \n",
    "    score=0\n",
    "    for i in str(text).split():\n",
    "        if i in pos_words:\n",
    "            score+=1\n",
    "        elif i in neg_words:\n",
    "            score-=1\n",
    "    return score\n",
    "    \n",
    "samp=data.loc[:1000, ['stars', 'textc']]\n",
    "samp['sentiment']=samp['textc'].apply(sentiment_score)\n",
    "print(samp.corr())  #to test the corr of star with sentiment, 0.44+, not bad.\n",
    "\n",
    "data['sentiment']=data['textc'].apply(sentiment_score)\n",
    "print(data.corr())  #sentiment now is 0.45 corr with stars; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use sentiment and remove old features; \n",
    "neg_words={'awkwardly', 'awkward', 'butt', 'discount', 'disappointed', 'disappoint', \n",
    "           'dismay', 'dumb', 'manner', 'sue', 'mean', 'meeting', 'monte', 'unfriendly', 'nasty', 'refuse', \n",
    "           'avoid', 'soggy', 'mistake', 'upset', 'filthy', 'sad', 'lousy', 'worst',  'unprofessional', \n",
    "           'rudely','unfortunately', 'screw', 'poorly', 'crap', 'crappy', 'tasteless', 'ignore', 'disaster',\n",
    "           'overpriced', 'wrong', 'sick', 'inedible', 'stale', 'dirty', 'disappointment', 'sorry', 'yuck', \n",
    "           'flavorless', 'mess', 'dont', 'slow', 'lack', 'wouldnt', 'disappointed', 'terrible', 'overprice', \n",
    "           'gross', 'waste', 'poor', 'leave', 'disgust', 'awful', 'mediocre', 'suck', 'bland', 'wasnt', \n",
    "           'rude', 'didnt', 'horrible', 'bad'}\n",
    "pos_words={'ambiance', 'ambience', 'awhile', 'delight', 'generous', 'hilarious', 'homey', 'hometown', 'home',\n",
    "           'performance', 'performer', 'recover', 'tremendous', 'fantastically', 'fantastic', 'friendly', 'funny', \n",
    "           'goodwill', 'successfully', 'amaze', 'amazing', 'amazingly', 'magic', 'favourite', 'favorite', 'extraordinarily',\n",
    "           'great', 'love', 'best', 'delicious', 'perfect', 'awesome', 'recommend', 'excellent', 'highly', 'fresh', \n",
    "           'friendly', 'wonderful', 'perfectly', 'like', 'beautiful', 'fabulous', 'cool', 'super', 'heaven', 'incredible'}\n",
    "\n",
    "###############to be ued for further word removal, while using sentiment###############\n",
    "####TURN OUT: DO NOT REMOVE!!!\n",
    "no_sentiment_feat=['feat_'+i for i in list(pos_words.union(neg_words))]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Num Features: %d\") % fit.n_features_\\nprint(\"Selected Features: %s\") % fit.support_\\nprint(\"Feature Ranking: %s\") % fit.ranking_\\n'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ty=pd.DataFrame(ytrain).reset_index(drop=True)\n",
    "ty2=pd.concat([ty, trainfull], axis=1)\n",
    "#trainfull, ytrain\n",
    "ty2.corr()\n",
    "'''\n",
    "##Feature Selection: https://machinelearningmastery.com/feature-selection-machine-learning-python/ \n",
    "from sklearn.feature_selection import RFE\n",
    "vs_rfe = RFE(LogisticRegression())\n",
    "vs_rfe.fit(trainfull, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature enginnering 1: use RFE for half selected features (performance slightly worse than full set); \n",
    "allrfe=list(zip(trainfull, vs_rfe.support_, vs_rfe.ranking_))\n",
    "yesfea=[i[0] for i in allrfe if i[1]==True] #list of supported features; \n",
    "nofea=[i[0] for i in allrfe if i[1]==False] #list of non-supported features; \n",
    "\n",
    "#combine trainfull (w/ tfidf) & label; \n",
    "labdf=pd.DataFrame(ytrain).reset_index(drop=True)\n",
    "d1=trainfull.loc[:, yesfea] #2417 col; \n",
    "d2=trainfull.loc[:, nofea]  #2418 col;\n",
    "\n",
    "df1=pd.concat([labdf, d1], axis=1)\n",
    "df2=pd.concat([labdf, d2], axis=1)\n",
    "\n",
    "df1corr=df1.corr().loc[:, ['stars']].sort_values(by='stars', ascending=False)\n",
    "df2corr=df2.corr().loc[:, ['stars']].sort_values(by='stars', ascending=False)\n",
    "\n",
    "print(df1corr.describe(percentiles=np.linspace(0, 1, 11))) #top and bottom 30% with CORR 0.01\n",
    "print(df2corr.describe(percentiles=np.linspace(0, 1, 11))) #top and bottom 20% with CORR 0.01\n",
    "\n",
    "#to use for model training; \n",
    "train_select=trainfull.loc[:, yesfea]\n",
    "test_select=testfull.loc[:, yesfea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering 2: use CORR(), and remove least relevant features (performance slightly worse than full set). \n",
    "train_label_full=pd.concat([pd.DataFrame(ytrain).reset_index(drop=True), trainfull], axis=1)\n",
    "cormat=train_label_full.corr().loc[:, ['stars']].sort_values(by='stars', ascending=False)\n",
    "\n",
    "print(cormat.describe(percentiles=[0.10, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]))\n",
    "print(len([i for i in cormat['stars'] if abs(i)<0.004]))\n",
    "cormat['features']=cormat.index\n",
    "\n",
    "more_corr_feat=list(cormat[abs(cormat['stars'])>0.004]['features'])   #list for further removal of features\n",
    "print(len(more_corr_feat))\n",
    "\n",
    "#to use for model training; \n",
    "train_select=trainfull.loc[:, more_corr_feat]\n",
    "train_select.drop('stars', axis=1, inplace=True)\n",
    "test_select=testfull.loc[:, more_corr_feat]\n",
    "test_select.drop('stars', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(cormat[abs(cormat['stars'])>0.05]['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression predictions with default hyparameters for Test\n",
      "\n",
      "Accuracy\n",
      "0.512666666667\n",
      "[[ 98  22  20  53  52]\n",
      " [ 40  43  38 122  43]\n",
      " [  7  17  70 279  71]\n",
      " [  6   2  27 641 352]\n",
      " [  2   1   4 304 686]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.40      0.49       245\n",
      "          2       0.51      0.15      0.23       286\n",
      "          3       0.44      0.16      0.23       444\n",
      "          4       0.46      0.62      0.53      1028\n",
      "          5       0.57      0.69      0.62       997\n",
      "\n",
      "avg / total       0.51      0.51      0.48      3000\n",
      "\n",
      "LogisticRegressionpredictions with default hyparameters for Train\n",
      "\n",
      "Accuracy\n",
      "0.677857142857\n"
     ]
    }
   ],
   "source": [
    "#remove half features from trainfull/testfull\n",
    "result=pd.DataFrame()\n",
    "rs=300\n",
    "global result\n",
    "\n",
    "model=LogisticRegression(random_state=rs)\n",
    "cname='LogisticRegression'\n",
    "\n",
    "model.fit(train_select, ytrain)\n",
    "pred=model.predict(test_select)\n",
    "tpred=model.predict(train_select)\n",
    "    \n",
    "predproba=pd.DataFrame(model.predict_proba(test_select))\n",
    "tpredproba=pd.DataFrame(model.predict_proba(train_select))\n",
    "\n",
    "print(cname + ' predictions with default hyparameters for Test'+'\\n')\n",
    "print('Accuracy')\n",
    "print(accuracy_score(ytest, pred, normalize=True))\n",
    "print(confusion_matrix(ytest, pred))\n",
    "print(classification_report(ytest, pred))  \n",
    "\n",
    "print(cname + 'predictions with default hyparameters for Train'+'\\n')\n",
    "print('Accuracy')\n",
    "print(accuracy_score(ytrain, tpred, normalize=True))\n",
    "\n",
    "#compare bad predictions of different models; \n",
    "result=pd.concat([result, pd.DataFrame(pred)], axis=1) #to merge the predicted labels back to the dataset;\n",
    "result.rename(columns={0:str(cname + '_pred')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "LogisticRegression predictions with default hyparameters for Test\n",
    "\n",
    "Accuracy\n",
    "0.514666666667\n",
    "[[ 96  19  26  50  54]\n",
    " [ 40  40  41 121  44]\n",
    " [  8  12  80 266  78]\n",
    " [  5   2  32 644 345]\n",
    " [  2   2   4 305 684]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          1       0.64      0.39      0.48       245\n",
    "          2       0.53      0.14      0.22       286\n",
    "          3       0.44      0.18      0.26       444\n",
    "          4       0.46      0.63      0.53      1028\n",
    "          5       0.57      0.69      0.62       997\n",
    "\n",
    "avg / total       0.52      0.51      0.49      3000\n",
    "\n",
    "LogisticRegressionpredictions with default hyparameters for Train\n",
    "\n",
    "Accuracy\n",
    "0.693857142857\n",
    "\n",
    "#####XGBoost with all features\n",
    "XGBoost predictions with default hyparameters for Test\n",
    "\n",
    "Accuracy\n",
    "0.479333333333\n",
    "[[ 70   8  13  77  77]\n",
    " [ 21  19  30 159  57]\n",
    " [  6   6  49 296  87]\n",
    " [  3   0  22 649 354]\n",
    " [  5   1   6 334 651]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          1       0.67      0.29      0.40       245\n",
    "          2       0.56      0.07      0.12       286\n",
    "          3       0.41      0.11      0.17       444\n",
    "          4       0.43      0.63      0.51      1028\n",
    "          5       0.53      0.65      0.59       997\n",
    "\n",
    "avg / total       0.49      0.48      0.44      3000\n",
    "\n",
    "XGBoostpredictions with default hyparameters for Train\n",
    "\n",
    "Accuracy\n",
    "0.601714285714\n",
    "\n",
    "#####Logistic with R.F.E half selected features (slightly worse than full set, others highly similar);\n",
    "LogisticRegression predictions with default hyparameters for Test\n",
    "\n",
    "Accuracy\n",
    "0.508666666667\n",
    "[[ 98  17  25  48  57]\n",
    " [ 46  33  41 120  46]\n",
    " [  9  12  77 266  80]\n",
    " [  5   1  36 637 349]\n",
    " [  4   3   6 303 681]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          1       0.60      0.40      0.48       245\n",
    "          2       0.50      0.12      0.19       286\n",
    "          3       0.42      0.17      0.24       444\n",
    "          4       0.46      0.62      0.53      1028\n",
    "          5       0.56      0.68      0.62       997\n",
    "\n",
    "avg / total       0.50      0.51      0.48      3000\n",
    "\n",
    "LogisticRegressionpredictions with default hyparameters for Train\n",
    "\n",
    "Accuracy\n",
    "0.678857142857\n",
    "\n",
    "\n",
    "#Threshold adjustment: save for the last\n",
    "#print(predproba)\n",
    "#print(type(ytest))\n",
    "\n",
    "a1=ytest.reset_index(drop=True)\n",
    "a2=pd.DataFrame(pred, columns=['predicted'])\n",
    "\n",
    "col = ['star_'+str(i) for i in range(1, 6)]\n",
    "predproba.columns = col\n",
    "\n",
    "a4=pd.concat([a1, a2, predproba], axis=1)\n",
    "a4.head()\n",
    "\n",
    "t5=a4[(a4['stars']==5) & (a4['predicted']==4)]\n",
    "print(len(t5))\n",
    "t5['star_5'].describe(percentiles=[0.01, 0.05, 0.10, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.75])\n",
    "#Star_5 threshold can adjust to 0.3, can save half of \"misclassified as star-4\" to be 5\n",
    "k=a4[(a4['star_5']<0.5) & (a4['star_5']>0.4) & (a4['star_4']>=0.5)]\n",
    "k['star_4'].describe(percentiles=[0.01, 0.05, 0.10, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, \n",
    "                                   0.5, 0.75])\n",
    "\n",
    "#https://stackoverflow.com/questions/28716241/controlling-the-threshold-in-logistic-regression-in-scikit-learn\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Conclusion')\n",
    "print('Sentiment score is very useful to corrent the misclassification problem for stars 1')\n",
    "print('RandomForest Regressor suggests very hard diffentiatio between stars 4 and 5 => combine both')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
